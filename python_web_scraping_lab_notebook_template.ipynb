{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxkQNVzddumRsYOsDdQW+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwaldenphd/web-scraping-python/blob/main/python_web_scraping_lab_notebook_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping in Python"
      ],
      "metadata": {
        "id": "7MzhNm9Tt6d3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff876fb9"
      },
      "source": [
        "Student Name: **Enter Your Name Here (Double click to edit)**\n",
        "<br>\n",
        "Net ID: **Enter Your NetID Here (Double click to edit)**\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Notebook Questions"
      ],
      "metadata": {
        "id": "tQARbhvayCrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q1A: Select another Wikipedia page that includes a table. From looking at the public web page, what data do you want to scrape from this web page (i.e. specific table, multiple tables, etc.)? What do you want the resulting data structure to look like (columns, rows, etc)?**\n",
        "\n",
        "### **Q1B: Take a look at the HTML for this page. What tags or other HTML components do you see around the section of the page you want to work with? For this question, we're thinking about how we will end up writing a program with <code>BeautifulSoup</code> to isolate a section of the web page.**\n",
        "\n",
        "### **Q1C: Develop an outline for a Python program that scrapes data from the web page you selected.**\n",
        "\n",
        "A preliminary workflow:\n",
        "- Load URL and create BeautifulSoup object\n",
        "- Isolate section of HTML with your table (either directly or extract from list)\n",
        "- Isolate table row elements (create list where each element is a table row)\n",
        "- Extract contents from row (isolate the pieces of information from each row)\n",
        "- Create Pandas DataFrame\n",
        "- Write extracted row contents to CSV file\n",
        "\n",
        "NOTE: This program will have a lot of moving parts! Starting with pseudocode to think about the underlying logic can help you organize the components you're building. As you start to build out your own program, think about where you can draw on sample code from the lab (or follow the same conceptual workflow).\n",
        "\n",
        "### **Q1D: What challenges or roadblocks did you face working on Q1C? How did you start to tackle or solve them?**"
      ],
      "metadata": {
        "id": "FembQg4kp_M2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2XYT06SpfJQ"
      },
      "source": [
        "**AnswerQ1**: Your answer here (double click to edit)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your codes here (double click to edit)\n",
        "\n",
        "# load url & create beautiful soup object\n",
        "\n",
        "# isolate page section\n",
        "\n",
        "# create list of rows"
      ],
      "metadata": {
        "id": "LWk_FYvnuw1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on single row\n",
        "\n",
        "# extract contents from row"
      ],
      "metadata": {
        "id": "Y9M-9WXkJSoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over rows in table\n",
        "\n",
        "# create pandas dataframe\n",
        "\n",
        "# write to csv file"
      ],
      "metadata": {
        "id": "Abi0xNTZJU28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q2A: Develop an outline for a Python program that uses `pd.read_html()` to scrape data from one of the web pages you select in Q6.**\n",
        "- *Wikipedia tables are fair game, but folks interested in sport data may want to head over to a [Sports Reference site](https://www.sports-reference.com/).*\n",
        "\n",
        "A preliminary workflow:\n",
        "- Use `pd.read_html()` to create a list of DataFrame objects\n",
        "- Identify which DataFrame object in the list is the table you want to work with\n",
        "- Isolate the list element to create a new DataFrame\n",
        "- Write the new DataFrame to a CSV file\n",
        "\n",
        "NOTE: Even though `pd.read_html()` has an easier learning curve than `BeautifulSoup`, this program will have a few moving parts! Starting with pseudocode to think about the underlying logic can help you organize the components you're building. As you start to build out your own program, think about where you can draw on sample code from the lab (or follow the same conceptual workflow).\n",
        "\n",
        "ANOTHER NOTE: For many Sports Reference pages, tables further down the page are buried in HTML comments. These tables will not show up when you use `pd.read_html()`. We can come back to these \"hidden tables\" in the final project, but for now, focus on the tables that do show up when you use `pd.read_html()`.\n",
        "\n",
        "### **Q2B: What challenges or roadblocks did you face working on Q2A? How did you start to tackle or solve them?**"
      ],
      "metadata": {
        "id": "QLEVgbtLMKFV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tihNYy4uis_c"
      },
      "source": [
        "**AnswerQ2:** Your answer here (double click to edit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roxNuL4SHkw3"
      },
      "outputs": [],
      "source": [
        "# your codes here (double click to edit)\n",
        "\n",
        "# create list of dataframes\n",
        "\n",
        "# isolate specific dataframe\n",
        "\n",
        "# write dataframe to csv file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q3A: Select another web page that includes unstructured text. From looking at the public web page, what text do you want to scrape from this web page (i.e. specific sections, multiple paragraphs, etc.)?**\n",
        "\n",
        "A few places to start for unstructured text:\n",
        "- [WikiSource](https://en.wikisource.org/wiki/Main_Page)(a library of texts that are not covered by copyright)\n",
        "  * [U.S. Presidential State of the Union Addresses](https://en.wikisource.org/wiki/Portal:State_of_the_Union_Speeches_by_United_States_Presidents)\n",
        "  * [U.S. Presidential Inaugural Speeches](https://en.wikisource.org/wiki/Portal:Inaugural_Speeches_by_United_States_Presidents)\n",
        "- [Project Gutenberg](https://www.gutenberg.org) (a library of literary works or texts that are not covered by copyright)\n",
        "\n",
        "### **Q3B: Take a look at the HTML for this page. What tags or other HTML components do you see around the section of the page you want to work with? For this question, we're thinking about how we will end up writing a program with `BeautifulSoup` to isolate a section of the web page.**\n",
        "\n",
        "### **Q3C: Develop an outline for a Python program that scrapes unstructured text from the web page you selected.**\n",
        "\n",
        "A preliminary workflow:\n",
        "- Load URL and create BeautifulSoup object\n",
        "- Isolate section of HTML with your text (either directly or extract from list)\n",
        "- IF NEEDED: Isolate text elements (create list where each element is a section of text)\n",
        "- IF NEEDED: Extract text contents (isolate text from each section/paragraph)\n",
        "- Write text to TXT file\n",
        "\n",
        "NOTE: This program will have a lot of moving parts! Starting with pseudocode to think about the underlying logic can help you organize the components you're building. As you start to build out your own program, think about where you can draw on sample code from the lab (or follow the same conceptual workflow).\n",
        "\n",
        "### **Q3D: What challenges or roadblocks did you face working on Q8C? What parts of the program do you understand/feel ready to develop at this point? What parts of the program are less clear?**"
      ],
      "metadata": {
        "id": "YKTd6gNTMOz2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4XagE0Va57Q"
      },
      "source": [
        "**AnswerQ3:** Your answer here (double click to edit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f8fxymXICRJ"
      },
      "outputs": [],
      "source": [
        "# your codes here (double click to edit)\n",
        "\n",
        "# load url & create beautiful soup object\n",
        "\n",
        "# isolate section of page with text\n",
        "\n",
        "# isolate text elements & extract text contents\n",
        "\n",
        "# write to TXT file"
      ]
    }
  ]
}